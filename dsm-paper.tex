\documentclass[a4paper,12pt]{article}
\usepackage{jae}
\usepackage{amsmath, bm, amsfonts}

\title{Spatial models for distance sampling data: recent developments and future directions}
\running{Spatial models for distance sampling}

\author{
David L. Miller$^{1*}$, \and
M. Louise Burt$^{2}$, \and
Eric A. Rexstad$^{2}$, \and 
Len Thomas$^{2}$.}

\affiliations{
\item Department of Natural Resources Science, University of Rhode Island, Kingston, Rhode Island 02881, USA
\item Centre for Research into Ecological and Environmental Modelling,\\ The Observatory, University of St. Andrews, St. Andrews KY16 9LZ, UK
}
\nwords{4158}
\ntables{0}
\nfig{6}
\nref{27}

\corr{\url{dave@ninepointeightone.net}}

\begin{document}

\maketitle

\begin{abstract}
  \noindent 
  
 %Summary. This is called the Abstract on the web submission site. The Summary should outline the purpose of the paper and the main results, conclusions and recommendations, using clear, factual, numbered statements. Authors should follow a formula in which point 1 sets the context and need for the work; point 2 indicates the approach and methods used; the next 2-3 points outline the main results; and the last point identifies the wider implications and relevance to management or policy. The final summary point must carry the subheading 'Synthesis and applications' and is the most important of all in maximising the impact of the paper. It should synthesise the paper's key messages and should be generic, seminal and accessible to non-specialists. The whole Summary should be readily understandable to all the Journal's readers and must not exceed 350 words.

\begin{enumerate}
	\item Our understanding of a biological population can be greatly enhanced by modelling their distribution in space and as a function of environmental covariates. Model-based inference may also be used to obtain abundance estimates from non-randomly designed surveys. 
	\item Density surface modelling achieves both of the above aims. DSMs combine distance sampling to account for uncertain detection and a spatial model for the effects of environmental covariates.
	\item We offer a comparison of recent advances in the field and consider the likely directions of future research. In particular we consider spatial modelling techniques that may be advantageous to applied ecologists.
	\item The methods discussed are freely available in \textsf{R} packages developed by the authors.
\end{enumerate}
 

\end{abstract}

\noindent \textbf{Keywords:} distance sampling, line transect sampling, point transect sampling, population abundance, population density, spatial modelling, wildlife surveys


\newpage

\section*{Introduction}
\label{s:intro}

When surveying biological populations it is increasingly common to record spatially referenced data; for example: coordinates of observations, habitat type, altitude or (if at sea) bathymetry. Spatial models allow for the vast databases of spatially-referenced data to be harnessed, allowing for interactions between environmental covariates and population densities to be investigated. Mapping the spatial distribution of a population can be extremely useful, especially when communicating results to non-experts. Recent advances in both methodology and software have made spatial modelling readily available to the non-specialist \citep[e.g.,][]{Wood:2006wz, Rue:2009tw}. Here we use the term ``spatial model'' to include any model that includes spatially referenced covariates, not just smooths of location. This article concerns combining spatial modelling techniques with distance sampling \citep{Buckland:2001vm, Buckland:2004ts}. 

Distance sampling takes plot sampling (counting the individuals or groups of objects in a strip or circle) and extends it to the case where detection is not certain. Observers travel along transect centre lines or stand at points and record the distance from the centre line or point to the object of interest ($y$). These distances are used to estimate the \textit{detection function}, $g(y)$ (bottom left panel, figure \ref{dolphin-eda}), by modelling the decrease in detectability with increasing distance from the line or point (conventional distance sampling, CDS). The detection function may also include animal/observer specific covariates \citep[multiple covariate distance sampling, MCDS;][]{Marques:2007vm}. From the fitted detection function, the probability of detection can be calculated. The estimated probability that an animal is detected, $\hat{p}_i$, can then be used to calculate abundance as
\begin{equation}
\hat{N} = \frac{A}{a} \sum_{i=1}^{n} \frac{1}{\hat{p}_i},
\label{ht-est}
\end{equation}
where $A$ is the area of the study region, $a$ is the area covered by the survey (i.e., the sum of the areas of all of the strips/circles) and the summation takes place over the $n$ observed individuals \citep[Chapter 3]{Buckland:2001vm}. In general distance sampling is more efficient than plot sampling since all objects observed are recorded and only later discard observations deemed to far away (outside of the \textit{truncation distance}).

When fitting the detection function in a distance sampling analysis, one assumes that the objects of interest are distributed according to some process \citep[Section 2.1]{Buckland:2001vm}. It is usually possible to design surveys such that a homogenous process can be assumed so, with respect to the line, objects are distributed uniformly. This can be achieved by e.g., ensuring that transect lines run perpendicular to geographical features that would attract (or repel) animals or by post-stratification \citep[Section 3.7]{Buckland:2001vm}. 

Estimators such as eqn. \ref{ht-est} are referred to as \textit{design-based} since they rely on the design of the study to ensure inference is valid. This article focusses on \textit{model-based} inference. Using spatially explicit models one can investigate the response of biological populations to biotic and abiotic covariates which vary over the survey area. Modelling the spatial process also enables the use data from badly designed or opportunistic surveys, for example incidental data arising from ``ecotourism'' cruises can be included in analyses \citep{Williams:2006tz}. 

Our aims in a DSM analysis are usually two-fold: (i) estimating overall abundance and (ii) investigating the relationship between abundance and environmental covariates. As with any predictions which are outside of the range of the data, one should heed the usual warnings regarding extrapolation. For example, in an terrestrial study, habitat may cause significant issues if there was not search effort in all habitats. Frequently, maps of abundance or density are required and any spurious predictions can be visually assessed, as well as by plotting a histogram of the predicted values. A sensible definition of the region of interest avoids prediction outside the range of the data.

The article focuses on those recent advances in spatial modelling of distance sampling data which are of most utility to applied ecologists. These new methods are available in the \textsf{R} packages \texttt{Distance} and \texttt{dsm}, and will soon be available in the popular Windows application Distance \citep{Thomas:2010cf}.

Throughout this article a motivating data set is used to illustrate the methods. These data are from a combination of several shipboard surveys conducted on pan-tropical spotted dolphins in the Gulf of Mexico. 47 observations of groups of dolphins The group size was recorded, as well as the Beaufort sea state at the time of the observation. Coordinates for each observation and bathymetry data were also available as covariates for the analysis. A complete example analysis is provided as an online appendix.

The rest of the article is structured as follows: we first describe the density surface modelling approach of \cite{Hedley:2004et}, explain how to estimate abundance and uncertainty. We then describe recent advances, practical advice regarding the model fitting, formulation and checking. Before concluding, we look at two alternative (but less mature) methods which take a rather more direct approach to modelling spatial distance sampling data.


\section*{Density surface modelling}
\label{s:dsm}

This section focuses on modelling the abundance/density estimation stage of distance sampling, using the ``count model'' of \cite{Hedley:2004et} which we refer to as \textit{density surface modelling} (DSM). Both line and point transects can be used but if lines are used then they are are split into contiguous \textit{segments} (indexed by $j$), which are of length $l_j$; small enough such that the density does not vary appreciably within a segment (usually making the segments approximately square, $2w\times 2w$, is sufficient). The general idea is to model the count or estimated abundance as a smooth function of covariates using a generalized additive model \cite[GAM;][]{Wood:2006wz}. For each segment or point, the response is modelled as a function of \textit{covariates at the environmental level} (the $z_{jk}$ with $k$ indexing the covariates, e.g., location, sea surface temperature, weather conditions). The covered area enters the model as an offset: the area surveyed at segment $j$ is $A_j = 2wl_j$ and at point $j$ is $A_j=w\pi^2$ (where $w$ is the truncation distance). 

\subsection*{Count as response}

The model for the count per segment is:
\begin{equation*}
\mathbb{E}(n_j) = \exp\left[ \log_e \left( \hat{p}_j A_j \right) + \beta_0 + \sum_k f_k\left(z_{jk}\right) \right],
\end{equation*}
where the $f_k$s are smooth functions of the covariates and $\beta_0$ is an intercept term. Multiplying the covered area ($A_j$) by the probability of detection ($\hat{p}_j$) gives the \textit{effective area} for segment $j$. If there are no covariates other than distance in the detection function then the probability of detection is constant (i.e., $\hat{p}_j=\hat{p}$, $\forall j$). The distribution of $n_j$ can then be modelled as overdispersed Poisson, negative binomial, or Tweedie distribution (see \textit{Recent developments}, below).

Figure \ref{dolphin-eda} (top panel) shows the raw observations from the dolphin data, along with the transect lines, overlaid on the depth data. Figure \ref{fits-depth} shows a GAM fitted to the dolphin data, the top panel shows predictions from a model where depth was the only covariate, the bottom panel shows predictions where a (bivariate) smooth of spatial location was also included. 

Abundance estimation is not the only information contained in these models. Plots of marginal smooths of the spatially referenced covariates show the relationships between the covariates and abundance. The effect of depth on abundance for the dolphin data can be seen in Figure \ref{depth-gamplot}. Between 0 and 500m there is a depth effect which then seems to level off (a straight line could be drawn inside the confidence band). This may indicate that the dolphins prefer water deeper than 500m, however the usual caveats inherent in interpreting results from observational studies apply.


\subsection*{Estimated abundance as response}

An alternative to modelling counts would be to use the per-segment/circle abundance can be estimated using distance sampling methods and the estimated counts used as the response. In this case we replace $n_j$ by:
\begin{equation*}
\hat{N}_j = \sum_{r=1}^{R_j} \frac{s_{jr}}{\hat{p}_j},
\end{equation*}
where $R_j$ is the number observations in segment $j$ and $s_{jr}$ is the size of the $r^\text{th}$ group in segment $j$ (if the animals occur individually then $s_{jr}=1$, $\forall j,r$). 

The following model is then fitted:
\begin{equation*}
\mathbb{E}(\hat{N}_j) = \exp\left[ \log_e \left( A_j \right) + \beta_0 + \sum_k f_k\left(\bm{z}_{jk}\right) \right],
\end{equation*}
where $\hat{N}_j$, as with $n_j$, is assumed to follow an overdispersed Poisson, negative binomial, or Tweedie distribution.

\subsubsection*{DSM with covariates at the observation level}

The above models only consider the case where the covariates are measured only at the segment/point level. Often covariates ($z_{ij}$, for individual/group $i$, segment/point $j$) are collected on the level of observations; for example sex, length or observer identity. In this case the probability of detection is a function of the individual level covariates $\hat{p}(z_i)$. Individual level covariates can be incorporated into the model by adopting the following estimator of the per-segment abundance:

\begin{equation*}
\hat{N}_j = \sum_{r=1}^{R_j} \frac{s_{jr}}{\hat{p}(z_{ij})}.
\end{equation*}

It is possible that bias is incurred by larger groups and therefore more visible groups. Including group size as a covariate in the detection function and fitting the above model is one solution. See \textit{Practical advice}, below, for more information on grouped populations.

By not including an offset, but instead dividing the count (or estimated abundance) by the area, we can also model density rather than abundance. We concentrate on abundance here, see \cite{Hedley:2004et} for further details.

\subsection*{Prediction}

To calculate an abundance estimate for some region of interest, the necessary covariates (those included in the model) must be available for the whole of that region, and they must also be available at the required resolution (using prediction grid cells that are smaller than the resolution of the spatially referenced data will not have an effect on abundance/density estimates). The areas of the segments/points are included as an offset in the model, so the area of the prediction cells must be included in the prediction data. Predictions can be made for the particular covariate levels and abundance estimates calculated for a particular area by summing predicted values over corresponding grid cells. 


\subsection*{Variance estimation}

Estimating the variance of abundances calculated using a DSM is not straight forward: uncertainty from the estimated parameters of the detection function must be incorporated into the spatial model. A second consideration is that in a line transect survey, adjacent segments are likely to be correlated; failing to account for this spatial autocorrelation will lead to artificially low variance estimates and hence misleadingly narrow confidence intervals.

\cite{Hedley:2004et} describe a method of calculating the variance in the abundance estimates using a parametric bootstrap, resampling from the residuals of the fitted model. The bootstrap is calculated as follows.

Denote the fitted values for the model to be $\hat{\bm{\eta}}$. For $b=1,\ldots,B$ (where $B$ is the number of resamples required).
\begin{enumerate}
	\item Resample (with replacement) the per-segment residuals, store the values in $\mathbf{r}_{b}$.
	\item Refit the model but with the response set to $\hat{\bm{\eta}}+\mathbf{r}_{b}$ (where $\hat{\bm{\eta}}$ are the fitted values from the orginal model).
	\item Take the predicted values for the new model and store them.
\end{enumerate}
From the predicted values stored in the last step, the per-location and abundance variance can be calculated in the usual manner. The total variance of the abundance estimate can then be found by combining the variance estimate from the bootstrap procedure with the variance of the probability of detection from the detection function model \citep[using the delta method;][]{Seber:2002ti}. This assumes that the two components of the variance are independent and the method does not not take into account spatial autocorrelation (the individual segments are treated as independent).

The above procedure assumes that there is no correlation in space between segments however, if many animals are observed in a particular segment then we might expect there to be high numbers in the adjacent segments. A moving block bootstrap \citep[MBB;][Section 8.6]{Efron:1993tv} can account for some of this spatial autocorrelation in the variance estimation. The segments are grouped together into overlapping blocks, (so if the block size is 5, block one is segments $1,\ldots,5$, block two is segments $2,\ldots,6$, and so on). Then, at step (2) above, resamples are taken of the blocks (i.e. groups of segments together) rather than individual segments within the transects. Using blocks should account for some of the autocorrelation between the segments, inflating the variances accordingly. However, since the block size dictates the maximum amount of spatial autocorrelation accounted for, this may not fully account for the autocorrelation. These bootstrap procedures can also be modified to take into account detection function uncertainty by generating new distances from the fitted detection function and then re-calculating the offset by fitting a detection function to the new distances.
 

\section*{Recent developments}
\label{s:recentadvances}

\subsubsection*{GAM uncertainty and variance propagation}

Rather than using a bootstrap, one can use GAM theory to construct uncertainty estimates for abundance estimates (and smooth terms) in a DSM. This merely requires that we take a Bayesian view and use the distribution of the parameters in the model \citep[further information can found in][page 245]{Wood:2006wz}. Such an approach means that the variance can be calculated without having to refit the model many times.
 
\cite{WILLIAMS:2011in} go a step further and incorporate the uncertainty in the estimation of the detection function into the variance of the spatial model, albeit only with environmental level covariates. Their procedure is as follows:
\begin{enumerate}
\item Fit a density surface model.
\item Re-fit the model with an additional random effects term. This term characterises the uncertainty in the estimation of the detection function (via the uncertainty of the probability of detection, $\hat{p}$).
\item Variance estimates of the abundance calculated as usual for the GAM will include uncertainty from the estimation of the detection function.
\end{enumerate}
We consider propagating the uncertainty in this manner not only to be more computationally efficient but also preferable from a technical perspective. The bootstrap does not fully account for spatial autocorrelation, assuming that the residuals are exchangeable when they are not will lead to wider confidence intervals. In simulation  the confidence intervals produced are narrower (than their bootstrap equivalents), while maintaining good coverage.

A common way to visualise uncertainty in a DSM is to plot the per-cell coefficient of variation by dividing the standard error for each cell by its predicted abundance. Figure \ref{cv-plot} shows a map of the coefficient of variation for the model which includes both location and depth covariates using the variance propagation method. 

\subsection*{Edge effects}
\label{s:leakage}

Recent work \citep{Ramsay:2002uo,Wang:2007tf,Wood:2008vo,ScottHayward:2011tc,Miller:2012tm} has highlighted the need to take care when smoothing over areas with complicated boundaries; e.g., those with rivers, peninsulae or islands. If two parts of the domain (either side of a mountain, say) are inappropriately linked by the model (the distance between the points is measured as a straight line, rather taking into account obstacles) then the boundary feature can be ``smoothed across'' leading to incorrect inference. Ensuring that a realistic spatial model has been fit to the data is essential for valid inference. The soap film smoother of \cite{Wood:2008vo} is particularly appealing as the model jointly estimates boundary conditions for a complex study area along with the interior smooth. This can be particularly helpful when uncertainty is estimated via a bootstrap as the model helps avoid large, unrealistic predictions which can plague other smoothers \citep{Bravington:2009vo}.

Even if the study area does not have a complicated boundary, edge effects can still be problematic. \cite{Miller:wx} show that when using global smoothers, smoothing towards the plane can cause the fitted surface to ``curl-up'' as predictions move further away from the data. They suggest the use of Duchon splines (a generalisation of thin plate regression splines) to alleviate the problem by smoothing toward the intercept.

\subsection*{Tweedie distribution}
\label{s:Tweedie}

The Tweedie distribution offers a very flexible alternative to the quasi-Poisson and negative binomial distributions as a response distribution when modelling count data \citep{Candy:2004tb}. Through the parameter $\lambda$, many common distributions arise; varying $\lambda$ between 1 (Poisson) and 2 (gamma) leads to a random variable which is a sum of $M$ gamma variables where $M$ is Poisson distributed \citep{Jorgensen:1987vg}. Although it is possible to perform optimization to find $\lambda$, this is generally seen as unnecessary as the distribution does not change appreciably when $\lambda$ is changed by less than $0.1$ (therefore trial and error is usually reasonable). Mark Bravington (pers. comm.) suggested plotting the square root of the absolute value of the residuals against fitted values; a ``flat'' plot (points forming a horizontal line) give an indication of a ``good'' value for $\lambda$. We additionally suggest using the metrics described in the next section for model selection.


\section*{Practical advice}
\label{s:practical}

Figure \ref{flow} shows a flow diagram of the modelling process for creating a density surface model for distance sampling data. The diagram shows which methods are compatible with each other and what the options are for modelling a particular data set.

In our experience, it is sensible obtain a detection function which fits the data as well as possible and only after a satisfactory detection function has been obtained, begin spatial modelling. A simple smooth of spatial location will given an idea of the distribution of the population, more covariates can then be added. A useful feature is the additional shrinkage available for GAMs which allow smooth terms to be removed from the model during fitting. Model selection can be performed for the detection function using AIC and model checking using goodness-of-fit tests given in \cite{Buckland:2004ts}. For the spatial model, smooth terms can be selected using as well as $p$-values. Generalized cross validation (GCV) score (or related metrics such as UnBiased Risk Estimator or REstricted Maximum Likelihood score; UBRE and REML, respectively) and percentage deviance explained are useful for model selection. We also highly recommend the use of standard GAM diagnostic plots. \cite{Wood:2006wz}, Chapter 5, provides practical information on GAM model selection and fitting.

In the dolphin analysis, we include a smooth of location. This not only doubles the percentage deviance explained (27.3\% to 52.7\%), it also allows us to account for spatial autocorrelation (in a primitive way). One can see this when comparing the two plots in Figure \ref{fits-depth} and the plot of the depth in Figure \ref{dolphin-eda}, the plot of the smooth of depth alone looks very similar to the raw plot of the depth data. A smooth of an environmental-level covariate such as depth can be very useful for assessing the relationships between abundance and the covariate. Caution should be employed when interpreting smooth relationships and abundance estimates, especially if there is poor coverage of covariate values. For example if there is a large agglomeration of individuals at a a high value of depth but no further observations occur at such a high value, then investigators should be skeptical of any relationship. For this reason a smooth of space is recommended for inclusion in candidate models. Limiting the ``wigglyness'' of smooths of spatial location can be a useful way of restricting their influence whilst still allowing them to ``mop up'' the residual spatial correlation in the data.


%depth only
%R-sq.(adj)                           : 0.0554 
%Deviance explained                   : 27.3%
%GCV score                          : 64.713
%
%xy + depth
%R-sq.(adj)                           : 0.292 
%Deviance explained                   : 52.7%
%GCV score                          : 52.248

In the analysis we have converted from latitude and longitude to kilometres from (27.01, -88.3), because the bivariate smoother which we use \citep[the thin plate spline;][]{Wood:2003tc} is isotropic: it treats the wigglyness of the smoother in each direction as equal. Moving 1 degree in latitude is not the same as moving 1 degree in longitude, so using kilometres from the centre of the study area is sensible (using SI units throughout also removes the need for conversion).

If animals occur in groups rather than individually, bias can be incurred due to larger groups being more visible than smaller groups. Bias due to group size can be assessed by regressing evaluations of the fitted detection function onto the logarithm of group size, then comparing the expected and observed values of the group size, if there is a large difference then it may be necessary to include size as a covariate in the detection function. The bottom right panel of figure \ref{dolphin-eda} shows a such a plot with the regression line overlaid.


\section*{Direct modelling of the spatial point process}
\label{s:direct}

Rather than use a GAM to model the spatially explicit part of the model, two recent articles have modelled the process using point processes \citep{cox1980point}. In both cases the density of object is governed by a spatially-varying \textit{itensity function}, which can include covariates in a similar manner to the GAM.

\cite{Johnson:2010gf} propose a point process-based model for distance sampling data (known as DSpat). They first assume that the locations of all individuals in the survey area (not just those observed) form a realisation of a Poisson process. Parameters of the intensity function are then estimated via standard maximum likelihood methods for point processes \citep{Baddeley:2000to}. In contrast to \cite{Hedley:2004et}, all parameters are estimated jointly so uncertainty from both the spatial pattern and the detection function is incorporated into variance estimates for the abundance. This also ensures that correlations between the detection function and underlying point process are estimated correctly (and do not falsely inflate or deflate variance estimates). The authors also address the issue of overdispersion unmodelled by spatial covariates using a post-hoc correction factor.

\cite{Niemi:2010kx} also use Poisson processes but incorporate them into a fully Bayesian approach. Unlike \cite{Johnson:2010gf} model fitting proceeds in two stages: first the detection function is fitted, then the spatial model (via MCMC) assuming the detection function parameters are known, so detection function uncertainty is not incorporated in the spatial model.

Both of the above Poisson process models do not account for group size, both stating that this could be included by considering a marked point process \citep[Section 5.5]{cox1980point}. Both methods offer direct modelling of the point process, although with some drawbacks compared to the methodology of \cite{Hedley:2004et}. It should be noted that the loss of efficiency from using DSM is not large \citep[p. 313]{Buckland:2004ts} because distances contain little information about spatial variation because transects are very thin compared to their lengths and circles are very small compared with study area.


\section*{Discussion}
\label{s:discussion}

The use of model-based inference for determining abundance and spatial distribution from distance sampling data presents new opportunities in the field of population assessment.   Inference from a sample of sightings to a population in a study area does not depend upon a random sample design, and therefore data from "platforms of opportunity" \citep{Williams:2006tz} can be used.

Unbiased estimates are dependent upon either (i) distribution of sampling effort being random throughout the study area (for design-based inference) or (ii) the model is correct (for model-based inference).  It is easier to have confidence in the former than in the latter because our models are always wrong. Nevertheless model-based inference will play an increasing role in population assessment as we attempt to squeeze more information from the data we gather.

The field is quickly evolving to allow modelling of more complex data building on the basic ideas of density surface modelling. We expect to see large advances in two areas: temporal inferences and the handling of spatial correlation. These should become more mainstream as modern spatio-temporal modelling techniques are adopted. \cite{Petersen:2011vy} provided a very basic framework for temporal modelling; their model included smooth terms both before and after the construction of an offshore windfarm. Spatial autocorrelation can be accounted for via approaches that explicitly introduce correlations such as generalized estimating equations \cite[GEEs;][]{Hardin:2003uf} or via mechanisms such as that of \cite{Skaug:2006gs}, which allowed observations to cluster according to one of several states (e.g. ``feeding'' or ``transit'') taking into account short-term agglomerations (``hot spots'').

\section*{Acknowledgments}

DLM wishes to thank Mark Bravington and Sharon Hedley for their help and patience in explaining and providing code for their variance propagation method.



\newpage

\bibliography{dsm-refs}

\newpage


\newpage


\section*{Figures}

\begin{figure}[h!]
  \caption{Top: the survey area, transect centrelines and observations with size of circle corresponding to the group size overlaid onto depth data; bottom left, histogram of observed distances with fitted detection function; bottom right, plot of evaluations of the fitted detection function at given distances versus the logarithm of group size with linear trend showing the relation between probability of detection (given distance) and group size.}
  \label{dolphin-eda}
  \begin{center}
    \includegraphics[width=\textwidth]{figs/depth-transects}\\
        \includegraphics[width=\textwidth]{figs/distances-groups}
  \end{center}
\end{figure}

\newpage

\begin{figure}[h!]
  \caption{Predictions for the dolphin data. Top: Predictions from the model using only depth as an explanatory variable, bottom: the model using both depth and location.}
  \label{fits-depth}
  \begin{center}
    \includegraphics[width=\textwidth]{figs/fit-depth}\\
    \includegraphics[width=\textwidth]{figs/fit-depth-xy}
  \end{center}
\end{figure}

\newpage

\begin{figure}[h!]
  \caption{Plot of the effect on the response of depth, note that it is possible to draw a straight line between 750m and 3000m within the confidence band (between the dashed lines), so the wiggles in the smooth may not be indicative of any relationship. What is clear is that there is some effect up to about 500m. The rug ticks at the bottom of the plot indicate we have good coverage of the range of depth values in the survey area. Note that the $y$ axis in such plots is on the scale of the link function ($\log$ in this case), so care should be taken in their interpretation.}
  \label{depth-gamplot}
  \begin{center}
    \includegraphics[width=\textwidth]{figs/fit-depth-gam}
  \end{center}
\end{figure}

\newpage

\begin{figure}[h!]
  \caption{Plot of coefficient of variation map for the model with smooths of both depth and location. Uncertainty was estimated using the variance propagation method of \cite{WILLIAMS:2011in}.}
  \label{cv-plot}
  \begin{center}
    \includegraphics[width=\textwidth]{figs/cvplot-varprop}
  \end{center}
\end{figure}

\newpage

\begin{figure}[h!]
  \caption{Flow diagram showing the modelling process for creating a density surface model.}
  \label{flow}
  \begin{center}
    \includegraphics[height=\textheight]{figs/flowdiagram-reduced}
  \end{center}
\end{figure}

\newpage

%\begin{figure}[h!]
%  \caption{Example of model diagnostics for the model which included both location and depth covariates for the dolphin data when a quasi-Poisson response distribution was specified. From top left clockwise:  1) normal Q-Q plot showing a problematic fit (the ``elbow'' in the points), 2) plot of (deviance) residuals against predicted values highlighting outliers and LOESS smooth (\cite{Cleveland:1979vd}) through the point overlaid, 3) a smooth of location fitted to the residuals showing some pattern left in the data and 4) the autocorrelogram. }
%  \label{dsm-check}
%  \begin{center}
%    \includegraphics[width=\textwidth]{figs/dsm-check}
%  \end{center}
%\end{figure}


\end{document}
